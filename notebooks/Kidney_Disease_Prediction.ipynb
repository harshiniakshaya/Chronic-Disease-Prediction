{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5be4aafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in c:\\users\\harsh\\appdata\\roaming\\python\\python311\\site-packages (1.25.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\harsh\\appdata\\roaming\\python\\python311\\site-packages (2.1.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\harsh\\appdata\\roaming\\python\\python311\\site-packages (1.6.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\harsh\\appdata\\roaming\\python\\python311\\site-packages (3.7.2)\n",
      "Requirement already satisfied: seaborn in c:\\users\\harsh\\appdata\\roaming\\python\\python311\\site-packages (0.13.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\harsh\\appdata\\roaming\\python\\python311\\site-packages (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\harsh\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\harsh\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\harsh\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\harsh\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\harsh\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\harsh\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\harsh\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\harsh\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (4.42.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\harsh\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\harsh\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\harsh\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\harsh\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\harsh\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\program files\\python311\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: INSTALL AND IMPORT LIBRARIES\n",
    "%pip install numpy pandas scikit-learn matplotlib seaborn joblib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99f77659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- First 5 rows of the dataset ---\n",
      "   id   age    bp     sg   al   su     rbc        pc         pcc          ba  \\\n",
      "0   0  48.0  80.0  1.020  1.0  0.0     NaN    normal  notpresent  notpresent   \n",
      "1   1   7.0  50.0  1.020  4.0  0.0     NaN    normal  notpresent  notpresent   \n",
      "2   2  62.0  80.0  1.010  2.0  3.0  normal    normal  notpresent  notpresent   \n",
      "3   3  48.0  70.0  1.005  4.0  0.0  normal  abnormal     present  notpresent   \n",
      "4   4  51.0  80.0  1.010  2.0  0.0  normal    normal  notpresent  notpresent   \n",
      "\n",
      "   ...  pcv    wc   rc  htn   dm  cad appet   pe  ane classification  \n",
      "0  ...   44  7800  5.2  yes  yes   no  good   no   no            ckd  \n",
      "1  ...   38  6000  NaN   no   no   no  good   no   no            ckd  \n",
      "2  ...   31  7500  NaN   no  yes   no  poor   no  yes            ckd  \n",
      "3  ...   32  6700  3.9  yes   no   no  poor  yes  yes            ckd  \n",
      "4  ...   35  7300  4.6   no   no   no  good   no   no            ckd  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "\n",
      "--- Dataset Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 26 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   id              400 non-null    int64  \n",
      " 1   age             391 non-null    float64\n",
      " 2   bp              388 non-null    float64\n",
      " 3   sg              353 non-null    float64\n",
      " 4   al              354 non-null    float64\n",
      " 5   su              351 non-null    float64\n",
      " 6   rbc             248 non-null    object \n",
      " 7   pc              335 non-null    object \n",
      " 8   pcc             396 non-null    object \n",
      " 9   ba              396 non-null    object \n",
      " 10  bgr             356 non-null    float64\n",
      " 11  bu              381 non-null    float64\n",
      " 12  sc              383 non-null    float64\n",
      " 13  sod             313 non-null    float64\n",
      " 14  pot             312 non-null    float64\n",
      " 15  hemo            348 non-null    float64\n",
      " 16  pcv             330 non-null    object \n",
      " 17  wc              295 non-null    object \n",
      " 18  rc              270 non-null    object \n",
      " 19  htn             398 non-null    object \n",
      " 20  dm              398 non-null    object \n",
      " 21  cad             398 non-null    object \n",
      " 22  appet           399 non-null    object \n",
      " 23  pe              399 non-null    object \n",
      " 24  ane             399 non-null    object \n",
      " 25  classification  400 non-null    object \n",
      "dtypes: float64(11), int64(1), object(14)\n",
      "memory usage: 81.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# STEP 2: LOAD AND INSPECT THE DATA\n",
    "file_path = '../data/kidney_disease.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(\"\\n--- First 5 rows of the dataset ---\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\n--- Dataset Info ---\")\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "636070f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data after cleaning ---\n",
      "    age    bp     sg   al   su  rbc   pc  pcc   ba    bgr  ...   pcv      wc  \\\n",
      "0  48.0  80.0  1.020  1.0  0.0  1.0  1.0  0.0  0.0  121.0  ...  44.0  7800.0   \n",
      "1   7.0  50.0  1.020  4.0  0.0  1.0  1.0  0.0  0.0  121.0  ...  38.0  6000.0   \n",
      "2  62.0  80.0  1.010  2.0  3.0  1.0  1.0  0.0  0.0  423.0  ...  31.0  7500.0   \n",
      "3  48.0  70.0  1.005  4.0  0.0  1.0  0.0  1.0  0.0  117.0  ...  32.0  6700.0   \n",
      "4  51.0  80.0  1.010  2.0  0.0  1.0  1.0  0.0  0.0  106.0  ...  35.0  7300.0   \n",
      "\n",
      "    rc  htn   dm  cad  appet   pe  ane  classification  \n",
      "0  5.2  1.0  1.0  0.0    1.0  0.0  0.0             1.0  \n",
      "1  4.8  0.0  0.0  0.0    1.0  0.0  0.0             1.0  \n",
      "2  4.8  0.0  1.0  0.0    0.0  0.0  1.0             1.0  \n",
      "3  3.9  1.0  0.0  0.0    0.0  1.0  1.0             1.0  \n",
      "4  4.6  0.0  0.0  0.0    1.0  0.0  0.0             1.0  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Total missing values after cleaning: 0\n"
     ]
    }
   ],
   "source": [
    "# STEP 3: DATA CLEANING\n",
    "\n",
    "# The 'id' column is just an identifier, so we don't need it.\n",
    "df.drop('id', axis=1, inplace=True)\n",
    "\n",
    "# The target column 'classification' has text 'ckd' or 'notckd'.\n",
    "# Machine learning models only understand numbers, so we'll convert them:\n",
    "# 'ckd' will become 1 (meaning \"disease present\")\n",
    "# 'notckd' will become 0 (meaning \"disease not present\")\n",
    "df['classification'] = df['classification'].map({'ckd': 1, 'notckd': 0})\n",
    "\n",
    "# Some columns that should be numbers are stored as text ('object').\n",
    "# We need to convert them to numeric types. 'coerce' will turn any bad values into 'NaN' (Not a Number).\n",
    "numeric_cols_to_fix = ['pcv', 'wc', 'rc']\n",
    "for col in numeric_cols_to_fix:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Other columns have 'yes'/'no', 'present'/'notpresent', etc.\n",
    "# We will convert all of these into 1s and 0s.\n",
    "binary_map_cols = ['htn', 'dm', 'cad', 'pe', 'ane']\n",
    "for col in binary_map_cols:\n",
    "    df[col] = df[col].map({'yes': 1, 'no': 0})\n",
    "df['appet'] = df['appet'].map({'good': 1, 'poor': 0})\n",
    "df['pcc'] = df['pcc'].map({'present': 1, 'notpresent': 0})\n",
    "df['ba'] = df['ba'].map({'present': 1, 'notpresent': 0})\n",
    "df['rbc'] = df['rbc'].map({'normal': 1, 'abnormal': 0})\n",
    "df['pc'] = df['pc'].map({'normal': 1, 'abnormal': 0})\n",
    "\n",
    "# Now we need to handle the missing values (NaNs).\n",
    "# We will fill them with the median (the middle value) of each column.\n",
    "# This is a good strategy because the median isn't skewed by very high or low values.\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object': # If it's a text column (which it shouldn't be now)\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "    else: # If it's a number column\n",
    "        df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "print(\"\\n--- Data after cleaning ---\")\n",
    "print(df.head())\n",
    "print(f\"\\nTotal missing values after cleaning: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efb8b01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4: SEPARATE FEATURES (X) AND TARGET (y)\n",
    "# 'X' is our input features (the patient's data).\n",
    "# 'y' is our target output (whether they have the disease or not).\n",
    "X = df.drop('classification', axis=1)\n",
    "y = df['classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad2ed99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5: SPLIT DATA INTO TRAINING AND TESTING SETS\n",
    "# We will use 80% of the data to teach the model (training set)\n",
    "# and 20% to test how well it learned (testing set).\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "747afacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 6: FEATURE SCALING\n",
    "# We need to put all our features on the same scale.\n",
    "# For example, 'age' (e.g., 50) is much larger than 'blood_urea' (e.g., 1.2).\n",
    "# Scaling fixes this, which helps the model learn better.\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "# Use the same scaler for the test data\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23d10efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training the model... ---\n",
      "Model training complete!\n"
     ]
    }
   ],
   "source": [
    "# STEP 7: TRAIN THE MODEL\n",
    "# Model: RandomForestClassifier\n",
    "print(\"\\n--- Training the model... ---\")\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(\"Model training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "718ae6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Performance ---\n",
      "Accuracy: 100.00%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        30\n",
      "         1.0       1.00      1.00      1.00        50\n",
      "\n",
      "    accuracy                           1.00        80\n",
      "   macro avg       1.00      1.00      1.00        80\n",
      "weighted avg       1.00      1.00      1.00        80\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[30  0]\n",
      " [ 0 50]]\n"
     ]
    }
   ],
   "source": [
    "# STEP 8: EVALUATE THE MODEL\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\n--- Model Performance ---\")\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6b452de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model saved to: ../saved_models/kidney_model.joblib\n",
      "Scaler saved to: ../saved_models/kidney_scaler.joblib\n"
     ]
    }
   ],
   "source": [
    "# STEP 9: SAVE THE MODEL AND SCALER\n",
    "model_path = '../saved_models/kidney_model.joblib'\n",
    "scaler_path = '../saved_models/kidney_scaler.joblib'\n",
    "\n",
    "joblib.dump(model, model_path)\n",
    "joblib.dump(scaler, scaler_path)\n",
    "\n",
    "print(f\"\\nModel saved to: {model_path}\")\n",
    "print(f\"Scaler saved to: {scaler_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
